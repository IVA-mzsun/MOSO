train:
  wandb: True
  device: ~
  local_rank: ~
  exp_name: Face_256rs_16f_fp16_sepmo

  deepspeed_config: config/deepspeed/deepspeed_base_fp16.json
  num_train_steps: 1000000
  num_valid_steps: 2500
  save_ckpt_steps: 5000
  gamma: cosine
  convert_loss_to_fp32: True

generation:
  name: ~
  batch_size: 1
  topk: -1
  samples: 500
  timesteps: 8
  show_process: True

tokenizer:
  num_frames: 16  # number of frames encoded by mocovqvae
  if_warp_token: False

vqvae:
  config_file: moco_vqvae/config/mocovqvae_wcd/FaceForensics/MoCoVQVAEwCD_im256_16frames_id4.yaml
  checkpoint: experiments/exp_vqvae/MoCoVQVAEwCD_Face_im256_16frames_id4_2022-06-09-23-57-05/MoCoVQVAE_wCD_iter250000.pth

dataset:
  name: FaceForensics
  cname: CustomUnconditionalDataset
  pin_memory: True
  shuffle: False
  num_worker: 4
  train:
    tokens_dir: datasets/FaceForensics/Face_tokens_im256_bg3_id4_mo5/train
  valid:
    tokens_dir: datasets/FaceForensics/Face_tokens_im256_bg3_id4_mo5/valid

model:
  name: Base_DS
  if_sep_mo: True

  transformer: bi
  num_layer: 16
  embed_dim: 758
  hidden_dim: 1024
  immediate_hidden_dim: 2048

  encoder_opt:
    num_head: 8
    switch_ln: False

  bg_token_length: 1024 # H-32, W-32
  id_token_length: 256  # H-16, W-16
  mo_token_length: 1024 # T-16, H-8, W-8
  max_input_length: 2305 # c+bg+id+mo
  dropout: 0.1

  checkpoint_path: ~
  pretrain_path: ~
  load_strict: ~