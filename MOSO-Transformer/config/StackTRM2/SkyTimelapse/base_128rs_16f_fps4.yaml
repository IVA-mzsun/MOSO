train:
  wandb: True
  device: ~
  local_rank: ~
  exp_name: Sky_128rs_16f_fps4_stacktrm2

  deepspeed_config: config/deepspeed/deepspeed_base_fp16_bs8.json
  num_train_steps: 1000000
  num_valid_steps: 2500
  save_ckpt_steps: 5000
  gamma: cosine
  convert_loss_to_fp32: True

generation:
  batch_size: 1
  topk: -1
  samples: 500
  timesteps: 8
  temperature: 0.3
  show_process: True

tokenizer:
  type: shareCB # [default, shareCB]
  num_frames: 16  # number of frames encoded by mocovqvae

vqvae:
  config_file: MoCoVQVAE/config/mocovqvae_wcd_sCB/SkyTimelapse/MoCoVQVAEwCD_im128_16frames_fps4+8+16+32.yaml
  checkpoint: experiments/exp_vqvae/MoCoVQVAEwCDsCB_Sky_im128_16frames_fps4+8+16+32_2022-07-02-13-35-16/MoCoVQVAE_wCD_shareCB_iter250000.pth

dataset:
  name: SkyTimelapse
  cname: CustomUnconditionalDataset
  pin_memory: True
  shuffle: False
  num_worker: 4
  train:
    tokens_dir: datasets/SkyTimelapse/tokens/im128_bg3_id3_mo4_fps4+8+16+32/train/FPS4
  valid:
    tokens_dir: datasets/SkyTimelapse/tokens/im128_bg3_id3_mo4_fps4+8+16+32/test/FPS4

model:
  name: StackTRM2_shareCB

  transformer: stack
  num_layer: 16
  mo_num_layer: 8
  embed_dim: 1024
  hidden_dim: 2048
  immediate_hidden_dim: 3072
  encoder_opt:
    num_head: 8

  bg_token_length: 256 # H-32, W-32
  id_token_length: 256  # H-16, W-16
  mo_token_length: 1024 # T-16, H-8, W-8
  max_input_length: 1032 # max(bg + id + T + cmd, mo + cmd)
  dropout: 0.1

  checkpoint_path: experiments/Sky_128rs_16f_fps4_stacktrm2_20220714-122303/ckpt
  pretrain_path: ~
  load_strict: True