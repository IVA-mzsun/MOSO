train:
  wandb: True
  device: ~
  local_rank: ~
  exp_name: Face_256rs_16f_fp16_LVQemb

  deepspeed_config: config/deepspeed/deepspeed_base_fp16_bs8.json
  num_train_steps: 1000000
  num_valid_steps: 2500
  save_ckpt_steps: 5000
  gamma: cosine
  convert_loss_to_fp32: True

generation:
  batch_size: 1
  topk: -1
  samples: 500
  timesteps: 8
  temperature: 0.3
  show_process: True

tokenizer:
  num_frames: 16  # number of frames encoded by mocovqvae

vqvae:
  config_file: moco_vqvae/config/mocovqvae_wcd/FaceForensics/MoCoVQVAEwCD_im256_16frames_id4.yaml
  checkpoint: experiments/exp_vqvae/MoCoVQVAEwCD_Face_im256_16frames_id4_2022-06-09-23-57-05/MoCoVQVAE_wCD_iter250000.pth

dataset:
  name: FaceForensics
  cname: CustomUnconditionalDataset
  pin_memory: True
  shuffle: False
  num_worker: 4
  train:
    tokens_dir: datasets/FaceForensics/Face_tokens_im256_bg3_id4_mo5_old/train
  valid:
    tokens_dir: datasets/FaceForensics/Face_tokens_im256_bg3_id4_mo5_old/valid

model:
  name: StackTRM_VQemb
  transformer: stack_vqemb # [stack, stack_vqemb]
  vqemb_open: True
  zmo_place: concat # [concat, sum]
  num_layer: 16
  mo_num_layer: 8
  embed_dim: 758
  hidden_dim: 1024
  immediate_hidden_dim: 2048
  encoder_opt:
    num_head: 8

  bg_token_length: 1024 # H-32, W-32
  id_token_length: 256  # H-16, W-16
  mo_token_length: 1024 # T-16, H-8, W-8
  max_input_length: 1300 # max(bg + id + T + cmd, mo + cmd)
  dropout: 0.1

  checkpoint_path: ~
  pretrain_path: ~
  load_strict: ~